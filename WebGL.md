# WebGL相关知识点
#### WebGL2是如何工作的
WebGL 和 GPU 到底在做什么
CPU 基本做了两部分事情： 
第一部分是处理顶点(数据流)，变成裁剪空间节点；
第二部分是基于第一部分的结果绘制像素

点着色器是用GLSL写的函数 每个顶点都用调用一次它。

对于每个像素，都会调用片段着色器。 它有一个 vec4 类型的输出变量，它指示绘制像素的颜色是什么

缓冲区是将顶点和将每个顶点数据传给GPU的方法
 gl.createBuffer创建一个缓冲区。 
 gl.bindBuffer将该缓冲区设置为正在处理的缓冲区。 
 gl.bufferData将数据复制到当前缓冲区中。

#### z buffer
Z缓冲器算法也叫深度缓冲器算法，属于图像空间消隐算法
该算法有帧缓冲器和深度缓冲器
intensity（x，y）——属性数组（帧缓冲器） 存储图像空间每个可见像素的光强或颜色
depth（x，y）——深度数组（z-buffer）存放图像空间每个可见像素的z坐标
算法思想：先将Z缓冲器中各单元的初始值置为最小值。
当要改变某个像素的颜色值时，首先检查当前多边形的深度值是否大于该像素原来的深度值（保存在该像素所对应的Z 缓冲器的单元中）
如果大于原来的z值，说明当前多边形更靠近观察点，用它的颜色替换像素原来的颜色
z-Buffer算法的优点：
Z-Buffer算法比较简单，也很直观
在象素级上以近物取代远物。与物体在屏幕上的出现 顺序是无关紧要的，有利于硬件实现
z-Buffer算法的缺点：
占用空间大
没有利用图形的相关性与连续性，这是z-buffer算法 的严重缺陷
更为严重的是，该算法是在像素级上的消隐算法

只用一个深度缓存变量zb的改进算法，存深度最小值，需要判断象素点(i,j)是否在pk的投影多边形之内

#### 点与多边形的包含性检测：
射线法
由被测点P处向 y = -∞方向作射线
交点个数是奇数，则被测点在 多边形内部
交点个数是偶数表示在多边形外部

弧长法
以p点为圆心，作单位圆，把边投影到单位圆上，对应一段段 弧长，规定逆时针为正，顺时针为负，计算弧长代数和
代数和为0，点在多边形外部
代数和为2π，点在多边形内部
代数和为π，点在多边形边上

以顶点符号为基础的弧长累加方法
#### 物体拾取的原理
射线追踪法
基于颜色的像素判断法(GPU)


#### 深度测试
深度值存储在每个片段里面（作为片段的z值），
当片段想要输出它的颜色时，将它的深度值和z缓冲进行比较，
如果当前的片段在其它片段之后，它将会被丢弃，否则将会覆盖。
这个过程称为深度测试(Depth Testing)


#### 性能优化
加载性能优化
    模型压缩 
        在保证外观效果的前提下，尽量使用较为精简(面数较少)的模型
        在模型制作完成之后，我们也应当尽量选取一些压缩比较高的模型格式
        例如 fbx、gltf 等进行模型传输
    gzip
        对于一些纯字符编码的模型，如 obj，dae 等，在服务端开启 gzip 压缩
        其实我们可以默认所有文件都开启，因为 js css 文件经过 gzip 压缩后传输量也会小很多
    gltf draco
        选取 gltf 格式加 draco 压缩的方式，可以得到较高的压缩比
        使用 draco 压缩并不是没有代价的，有时候可能会造成模型的外观损坏
        对于小的模型，网络传输较快的，也就没必要上 draco 压缩了
    自定义格式
        将模型数据做成二进制的形式进行传输和加载，这样灵活性比较高
    贴图压缩
        Basis Universal 支持多种常用的压缩纹理格式，将 png 转换为 basis 文件后，大小与 jpg 格式差不多，但在 GPU 上比 png/jpg 小 6-8 倍
    分包流式加载
        对于大的场景，特别是 BIM 或者 GIS 场景，如果把所有模型全部加装完成了再展示，可能会让用户等待时间过久
        所以，我们可以采取分包流式加载的方式，每个包加载一部分的模型，加载解析完成后即丢到渲染主线程中进行渲染
        我们一般会使用 worker 进行数据的加载和解析处理，这样保证了加载的线程和主线程是隔离的，不会产生加载解析模型过程中产生的 UI 卡顿
        同时，如果我们想要达到并行加载和解析的效果，可以开多个 worker 进行多线程的同时加载解析工作
    使用缓存
        使用 cdn 文件服务，浏览器文件缓存、indexeddb 前端缓存等
    使用 CDN
        如果模型场景都放在一台服务器上，加载过程中必定会对服务器的带宽带来一定压力
        所以使用 cdn 做静态资源的文件服务
    使用 indexedDB
        indexedDB 具有良好的查询性能，超大的存储空间（理论上磁盘剩余空间的一半左右），以及支持二进制存储等优良特性，比较适合做前端模型以及贴图数据的缓存。
        在使用了 indexeddb 做前端缓存之后，可以做到首次加载之后，对大场景的数据进行秒级加载的超高性能 ，大大提升了用户频繁打开大场景的操作体验。
        因此，有些 Webgl 引擎(例如 Babylon.js )已经在引擎级别对 indexedDB 缓存做了支持。开发者只需要简单配置，即可打开缓存，优化加载体验。
渲染帧率优化
    目的是尽量减少 drawcall（opengl state 切换带来的性能损耗），减少向 GPU 提交的数据量（带宽压力）
    各种剔除 Culling
        视椎体剔除（Frustum Culling） 只有在视椎体内的物体才能被渲染出来
            一般是遍历视椎体的 6 个面，算出物体的中心到面的最小距离（带正负方向的）与包围球的半径做比较，如果小于半径，就表示在外面
        背面渲染剔除(Backface Culling) 
            原生 webgl 中使用 gl.enable(gl.CULL_FACE); 来开启背面剔除。
            在 threejs 中可以使用 material 的 side 属性指定 front 进行单面渲染
        遮挡剔除(Occlusion Culling) 
            遮挡剔除是指在相机剔除后，在视野范围内仍然有许多物体直接有遮挡关系的，不需要进行渲染，
            虽然 gpu 有深度测试，会将有遮挡的物体进行剔除，
            但是我们仍然希望在提交 GPU 之前对遮挡关系进行判断，提前剔除掉一些东西，减少渲染压力
    合批 batch
        首先是材质相同的进行 batch，材质不同的无法进行 batch
        一个 batch 其实就是一个 drawcall，对应的其实一种材质，不同种材质效果需要使用不同的 shader 实现所以无法实现合批展示。
        如果你使用的 threejs，可以选择使用 geometry 的 merge 方法在前端进行合并 batch，
        或者手工进行顶点 loop 循环合并顶点，其实原理差不多
    instance
        实例化其实也是渲染优化中常用的技术，特别适合那些外观一致大量重复的渲染
        在 instance 渲染的时候，我们不需要传入大量的顶点数据（只需要传入每个 instance 的 matrix 数据）
        而是共享一份顶点数据，这样可以大大降低显存的使用率，降低显存带宽。
        在 webgl 中我们使用的是ANGLE_instanced_arrays扩展来实现 instance 渲染。
        但是值得注意的是，instance 的使用所带来一些额外处理，比如单个物体的选择操作等问题
    LOD
        (Level of Details）技术指的是将场景中的模型按不同精度分为 N 套,按照模型与相机的距离远近，动态切换模型的精度，
        距离相机较近的模型采用精细模型展示，而距离相机较远的模型使用较为粗糙的模型进行展示。
        对于大的场景，使用 LOD 技术也是一个有效提升帧率的手段，可以有效减少整个场景中的渲染三角面数。
内存管理优化
    对于重型 webgl 应用，特别是 BIM、GIS 场景，有时候，我们需要加载多个大型模型，例如 cesium 还需要能够支持整个地球数据的加载。
    这就需要我们对内存有着较好的控制
    一方面，我们需要在不适用对象的时候，及时销毁对象，释放 JS 内存。
    同时对于模型数据，大量的顶点、法线等等 buffer 数据也是非常占用内存的。
    我们可以在 js 推送完数据之后，将这部分数据从内存中释放掉，从而降低 JS 的内存压力。
    对于 v8 引擎来说 32 位的 JS heap 最多能到 3.8G 左右，如果不及时释放内存，很容易内存爆掉，导致浏览器 crash。
    如果使用 threejs 进行渲染，BufferAttribute包含一个onUpload回调函数，在数据推送到 GPU 之后调用。
    我们可以在回调函数中释放掉 js 中的数据。值得注意的是，这个回调函数只在第一次的时候有用，在 attribute 更新 update 的时候，并不会触发，笔者认为这是个 bug 提交了 pr 给 threejs，不过似乎 threejs 的作者doob并不十分感冒，最终没有 merge 这个 pr。
交互操作优化
    交互操作中一个常见的问题就是模型拾取。
    一般普通的三维场景中，我们常用的是射线拾取的方式，遍历场景中的模型，进行模型的相交测试。
    但是由于场景非常大，可能会导致整个遍历非常耗时。
    所以我们要对拾取进行优化。常见的优化方式有使用 GPU 拾取、以及使用八叉树进行加速遍历等方式。
    gpu 拾取 
        一般做法是给每个 mesh 一种颜色 然后渲染绘制一遍，在鼠标点所在的位置调用 readPixel 读取像素颜色，
        根据颜色与模型的对应关系，反推当前拾取到的颜色对应的 mesh
    八叉树优化
        一般是使用八叉树的数据结构，将整个场景中的模型放入八叉树的不同 cell 中，
        由于八叉树类似空间范围内的二分查找，所以能够非常迅速将查找范围落在最终需要遍历的模型上。
        从而达到加速模型场景遍历的目的。对于八叉树的实现网上有很多的版本，大家可以参考，一般笔者使用的是稀松八叉树。

#### 帧缓冲
#### 几何: 怎么判断点在三角形内
#### 实例化渲染
#### 模型的优化: draco
#### 大量物体的渲染方法:合并
#### mv矩阵

#### 灯光
#### 不同相机模型

#### 3d的graphic pipeline
Application CPU负责，把各种几何体信息输送到Geometry阶段，如点、线、三角形。
    这个阶段是不需要细分子管线的，因为是在CPU处理
    假设是单线程，那么并没有管线处理的能力
    不过可以用多核多线程，来实现并行计算
Geometry
    model and view transform
    vertex shading
    projection
    clipping
    screen mapping
Rasterizer 
    triangle setup
    triangle traversal 
        fragment是指被光栅化阶段的三角形覆盖(全覆盖或部分覆盖）到的像素格子其中之一
        找出每个三角形的fragments，就叫triangle traversal，或叫scan conversion
    pixel shading
    merging
        depth test和stencil test发生在这个阶段
#### MVP变换详解（物体从自身坐标系到屏幕渲染之间发生的矩阵转换）
MVP变换：将我们已经构建好的各种3维模型映射到屏幕这个2维坐标中
参与 MVP 变换的信息包括点、矢量、法线、切线等
模型变换（Model）：将模型空间转换到世界空间
观察变换（View）：将世界空间转换到观察空间
投影变换（Projection）：将观察空间转换到裁剪空间
最后要获取屏幕坐标还需要一步：屏幕映射，又叫视口变换
屏幕映射：获取对应屏幕的 2D 坐标

模型变换(Model)
本质就是旋转，平移，缩放
模型自身会携带模型坐标的原点信息等，再结合世界坐标还是很好变换的

观察变换(View)
在我的理解下，M 和 V 变换本质上是同一种类型的变换
比较快速的方法是把整个摄像机坐标空间移动到世界坐标使二者重合再反转 z 轴（不是真的移动摄像机），即在物体与摄像机相对位置不变的情况下让摄像机位于（0，0，0），将变换摄像机的矩阵作用于物体上就可得到观察空间中的坐标

投影(Projection)
投影要为裁剪做准备
视野是有限的，所以在视野外（视锥外）的东西是不需要显示的
而用六个裁剪平面（视锥的六个面）直接判断相对复杂
所以需要投影操作将视锥变成裁剪空间，再通过齐次除法，
将裁剪空间变成CVV(Canonical View Volume)，
OpenGL中CVV就是一个[-1,1]^3的正方体（下面讨论这种），
DirectX中的 z 分量稍微不同是[0,1]，
此时的坐标就是 NDC(Normalized Device Coordinates，归一化设备坐标)
不考虑 z 轴的情况下，投影是将所有点投影到近裁剪平面上（个人认为可以理解为摄像机拍到的画面，一张特殊的二维相片），然后放缩到[-1,1]^2的正方形平面
